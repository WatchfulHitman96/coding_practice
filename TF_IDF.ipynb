{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtpPDcLNGgOCiqxDumBUDd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J860dKK-TLoH",
        "outputId": "fd5b7a0d-bbdb-404b-bd7c-dc6ec133dc1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    my      face       bed  sat       dog   on       cat  the\n",
            "0  0.0  0.115525  0.000000  0.0  0.000000  0.0  0.115525  0.0\n",
            "1  0.0  0.000000  0.115525  0.0  0.115525  0.0  0.000000  0.0\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "# 1. Our Dataset\n",
        "docA = \"the cat sat on my face\"\n",
        "docB = \"the dog sat on my bed\"\n",
        "\n",
        "# Split documents into word lists\n",
        "bowA = docA.split(\" \")\n",
        "bowB = docB.split(\" \")\n",
        "wordSet = set(bowA).union(set(bowB)) # Get all unique words\n",
        "\n",
        "# --- Step 1: Compute TF (Term Frequency) ---\n",
        "def computeTF(wordDict, bow):\n",
        "    tfDict = {}\n",
        "    bowCount = len(bow)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count / float(bowCount)\n",
        "    return tfDict\n",
        "\n",
        "# Count words in each document\n",
        "wordDictA = dict.fromkeys(wordSet, 0)\n",
        "wordDictB = dict.fromkeys(wordSet, 0)\n",
        "\n",
        "for word in bowA:\n",
        "    wordDictA[word] += 1\n",
        "\n",
        "for word in bowB:\n",
        "    wordDictB[word] += 1\n",
        "\n",
        "tfA = computeTF(wordDictA, bowA)\n",
        "tfB = computeTF(wordDictB, bowB)\n",
        "\n",
        "# --- Step 2: Compute IDF (Inverse Document Frequency) ---\n",
        "def computeIDF(docList):\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "\n",
        "    # Count how many documents contain the word 't'\n",
        "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "    for doc in docList:\n",
        "        for word, val in doc.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "\n",
        "    # Apply the IDF formula: log(Total Docs / Docs with word)\n",
        "    for word, val in idfDict.items():\n",
        "        if val > 0:\n",
        "            idfDict[word] = math.log(N / float(val))\n",
        "        else:\n",
        "            idfDict[word] = 0\n",
        "\n",
        "    return idfDict\n",
        "\n",
        "idfs = computeIDF([wordDictA, wordDictB])\n",
        "\n",
        "# --- Step 3: Compute TF-IDF ---\n",
        "def computeTFIDF(tfBow, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBow.items():\n",
        "        tfidf[word] = val * idfs[word]\n",
        "    return tfidf\n",
        "\n",
        "tfidfA = computeTFIDF(tfA, idfs)\n",
        "tfidfB = computeTFIDF(tfB, idfs)\n",
        "\n",
        "# Print Results\n",
        "import pandas as pd\n",
        "df = pd.DataFrame([tfidfA, tfidfB])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "luOLs5c3TdxC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}